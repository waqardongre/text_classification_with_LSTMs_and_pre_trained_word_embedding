{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIf725o-Z2XW"
      },
      "source": [
        "## References : \n",
        "1. https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
        "2. https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7_YLiMAZ2Xh"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eH-R13geZ2Xl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3zoddqlZ2Xp"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this project, we show how to train a text classification model that uses pre-trained\n",
        "word embeddings.\n",
        "\n",
        "We'll work with the AclImdb dataset, a set of total 25,000 with positive 12,500 positive and 12,500 negative movie reviews.\n",
        "\n",
        "For the pre-trained word embeddings, we'll use\n",
        "[GloVe embeddings](http://nlp.stanford.edu/projects/glove/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93sPZ6W5KlxW",
        "outputId": "541ad728-778a-4e20-aa66-f050e1ae43e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Uncomment below 2 lines if you are using google drive. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjOfI1v6Z2Xr"
      },
      "source": [
        "## Download the AclImdb data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eH9LpPFKlxZ"
      },
      "source": [
        "### Download data from here: 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz' and place in your root of project folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYmaYUKIKlxc"
      },
      "source": [
        "### uncomment and run script in below cell only one time to extract this in the root of your project folder. Comment after executed. Update the paths according to your project path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZcNzuM9slOd3"
      },
      "outputs": [],
      "source": [
        "#!tar -xzvf '/content/drive/MyDrive/DS/nlp_movie_ratings/aclImdb_v1.tar.gz' -C '/content/drive/MyDrive/DS/nlp_movie_ratings/root'     #[run this cell to extract tar.gz files]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiawiRT0Klxg"
      },
      "source": [
        "### Set the path to the folder where data is extracted in your project folder in this main_path variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Asz_1JLplLw_"
      },
      "outputs": [],
      "source": [
        "#main_path = \"/content/drive/MyDrive/DS/nlp_movie_ratings/root/aclImdb/\" # wenoff\n",
        "main_path = \"/content/drive/MyDrive/DS/nlp_movie_ratings/root/aclImdb/\" # wazu\n",
        "#main_path = \"/content/drive/MyDrive/DSs/nlp_movie_ratings/root/aclImdb/\" # dowa and jale\n",
        "#main_path = \"/content/drive/MyDrive/datasets/nlp_movie_ratings/root/aclImdb/\" # wado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#path_to_glove_file = \"/content/drive/MyDrive/DS/21a/glove6B/glove.6B.100d.txt\" # wadon\n",
        "path_to_glove_file = \"/content/drive/MyDrive/DS/21a/glove6B/glove.6B.100d.txt\" # wazul"
      ],
      "metadata": {
        "id": "LRgIHJuyen-X"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA-l7gr_Z2Xt"
      },
      "source": [
        "## Let's take a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgsZMRzCZ2Xu",
        "outputId": "737fc41a-e95d-4ba8-e25e-ad80b033315c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of directories: 8\n",
            "Directory names: ['labeledBow.feat', 'neg', 'pos', 'unsup', 'unsupBow.feat', 'urls_neg.txt', 'urls_pos.txt', 'urls_unsup.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(main_path).parent / \"aclImdb/train\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", sorted(dirnames))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1cN5JDVZ2Xw"
      },
      "source": [
        "Here's a example of what one file contains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKrB-S59Z2Xy",
        "outputId": "3c0f381a-2961-4715-8e0b-6658c66f3fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
          ]
        }
      ],
      "source": [
        "print(open(data_dir / \"pos\" / \"0_9.txt\").read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOkFzeAIZ2Xz"
      },
      "source": [
        "As you can see, there are header lines that are leaking the file's category, either\n",
        "explicitly (the first line is literally the category name), or implicitly, e.g. via the\n",
        "`Organization` filed. Let's get rid of the headers:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5y1Rteg59mG"
      },
      "source": [
        "Setting total data size from total 25000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "7Mu1RZse59Uf"
      },
      "outputs": [],
      "source": [
        "#no_of_rows = 2500 # for both class - total 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaFr71INZ2X0",
        "outputId": "c9c0cb07-327c-4d4b-8a82-09d35102ac11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing pos, 12500 files found\n",
            "Processing neg, 12500 files found\n",
            "Classes: ['pos', 'neg']\n",
            "Number of samples: 25000\n"
          ]
        }
      ],
      "source": [
        "samples = []\n",
        "labels = []\n",
        "class_names = dirnames = ['pos', 'neg']\n",
        "class_index = 0\n",
        "for dirname in dirnames:\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath) # [:no_of_rows]\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding=\"latin-1\")\n",
        "        content = f.read()\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qvL465cZ2X2"
      },
      "source": [
        "## Shuffle and split the data into training & validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "dyVeYTF0Z2X3"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data\n",
        "seed = 9\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.05\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgH2HuoHZ2X4"
      },
      "source": [
        "## Create a vocabulary index by using imdb vocabulary given with the dataset\n",
        "\n",
        "Let's use the `TextVectorization` to index the vocabulary found in the dataset.\n",
        "Later, we'll use the same layer instance to vectorize the samples.\n",
        "\n",
        "Our layer will only consider the top 5,000 words, and will truncate or pad sequences to\n",
        "be actually 200 tokens long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "OFCZogR5Z2X5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=5000, output_sequence_length=200, vocabulary = main_path + \"imdb.vocab\")\n",
        "#text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "#vectorizer.adapt(text_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj8RKvFjZ2X5"
      },
      "source": [
        "You can retrieve the computed vocabulary used via `vectorizer.get_vocabulary()`. Let's\n",
        "print the top 5 words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DzN7iBhZ2X6",
        "outputId": "33be9532-31be-4d99-c4db-b64463a2612c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'and', 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "vectorizer.get_vocabulary()[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y304YbzZ2X7"
      },
      "source": [
        "Let's vectorize a test sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "uRqXL7pyZ2X7"
      },
      "outputs": [],
      "source": [
        "#output = vectorizer([[\"the cat sat on the mat\"]])\n",
        "#output.numpy()[0, :6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKwhBt6YZ2X8"
      },
      "source": [
        "As you can see, \"the\" gets represented as \"2\". Why not 0, given that \"the\" was the first\n",
        "word in the vocabulary? That's because index 0 is reserved for padding and index 1 is\n",
        "reserved for \"out of vocabulary\" tokens.\n",
        "\n",
        "Here's a dict mapping words to their indices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "118H6wn1Z2X8"
      },
      "outputs": [],
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVAtIFW2Z2X9"
      },
      "source": [
        "As you can see, we obtain the same encoding as above for our test sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtPdIuKnDZTn",
        "outputId": "2ef082cd-49c2-417f-f254-814d0853cb67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "word_index[\"word\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Imp9-tRZ2X9",
        "outputId": "c35457de-3ab1-4610-b003-29c1307ca771"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1080, 1777, 20, 2, 12332]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[w] for w in test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "u4h6-lKNKlx9"
      },
      "outputs": [],
      "source": [
        "# Saving vectorizer for deployment\n",
        "\n",
        "# Reference https://stackoverflow.com/questions/65103526/how-to-save-textvectorization-to-disk-in-tensorflow\n",
        "\n",
        "# Pickle the config and weights\n",
        "pickle.dump({'config': vectorizer.get_config(),\n",
        "             'weights': vectorizer.get_weights()}\n",
        "            , open(main_path + \"vectorizer.pkl\", \"wb\"))\n",
        "\n",
        "# Later you can unpickle and use \n",
        "# `config` to create object and \n",
        "# `weights` to load the trained weights. \n",
        "\n",
        "# from_disk = pickle.load(open(main_path + \"vectorizer.pkl\", \"rb\"))\n",
        "# vectorizer = TextVectorization.from_config(from_disk['config'])\n",
        "# vectorizer.set_weights(from_disk['weights'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL9yyfYfZ2X-"
      },
      "source": [
        "## Load pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRsjr3eGZ2X-"
      },
      "source": [
        "Let's download pre-trained GloVe embeddings (a 822M zip file).\n",
        "\n",
        "You'll need to run the following commands:\n",
        "\n",
        "```\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "gnYSBzVFtEr2"
      },
      "outputs": [],
      "source": [
        "# one time only\n",
        "#!unzip \"/content/drive/MyDrive/DSs/21a/glove.6B.zip\" -d \"/content/drive/MyDrive/DSs/21a/glove6B/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2lgjhfxZ2X_"
      },
      "source": [
        "The archive contains text-encoded vectors of various sizes: 50-dimensional,\n",
        "100-dimensional, 200-dimensional, 300-dimensional. We'll use the 100D ones.\n",
        "\n",
        "Let's make a dict mapping words (strings) to their NumPy vector representation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_bCW8uIZ2X_",
        "outputId": "d7482c12-b1e3-48e7-f5c8-7625127df8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKG0o1fxZ2YA"
      },
      "source": [
        "Now, let's prepare a corresponding embedding matrix that we can use in a Keras\n",
        "`Embedding` layer. It's a simple NumPy matrix where entry at index `i` is the pre-trained\n",
        "vector for the word of index `i` in our `vectorizer`'s vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCF1QrnbZ2YA",
        "outputId": "77752a9c-cd16-4ac0-d704-57913e17f4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 62596 words (26933 misses)\n"
          ]
        }
      ],
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dajYaHrjZ2YB"
      },
      "source": [
        "Next, we load the pre-trained word embeddings matrix into an `Embedding` layer.\n",
        "\n",
        "Note that we set `trainable=False` so as to keep the embeddings fixed (we don't want to\n",
        "update them during training)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0adau9i-dSY",
        "outputId": "98c9a0b8-0315-49ff-ac8f-52d560ee8730"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89531, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "num_tokens, embedding_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "dWRwyZsCZ2YB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yiKvOnDZ2YB"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "A simple 1D convnet with global max pooling and a classifier at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "kOZFWO9aZ2YC"
      },
      "outputs": [],
      "source": [
        "def create_rnn(cell_units = 100, dropout = 0.2):\n",
        "    # Initialising the RNN\n",
        "    regressor = Sequential()\n",
        "\n",
        "    regressor.add(embedding_layer)\n",
        "\n",
        "    # Adding a 1st LSTM layer and some Dropout regularisation\n",
        "    regressor.add(LSTM(units = cell_units, return_sequences = True, dropout=dropout, recurrent_dropout=dropout))\n",
        "\n",
        "    # Adding a 2nd LSTM layer and some Dropout regularisation\n",
        "    regressor.add(LSTM(units = cell_units, return_sequences = True, dropout=dropout, recurrent_dropout=dropout))\n",
        "\n",
        "    # Adding 3rd LSTM layer and some Dropout regularisation\n",
        "    regressor.add(LSTM(units = cell_units, dropout=dropout, recurrent_dropout=dropout))\n",
        "\n",
        "    # Adding the output layer\n",
        "    regressor.add(Dense(units = 1, activation='sigmoid'))\n",
        "\n",
        "    return regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKmbSq_PZ2YC"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "First, convert our list-of-strings data to NumPy arrays of integer indices. The arrays\n",
        "are right-padded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "eYo86bSvZ2YD"
      },
      "outputs": [],
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdsBdKDK8d4h",
        "outputId": "2524a9d5-7e84-423d-9050-72c8e492addd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23750, 200), (23750,), (1250, 200), (1250,))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg0eA5YB04Kq",
        "outputId": "ad16e7fd-1bdb-4bc2-8694-938644c8b355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/400\n",
            "12/12 [==============================] - 48s 3s/step - loss: 0.6889 - accuracy: 0.5248 - val_loss: 0.6833 - val_accuracy: 0.5368\n",
            "Epoch 2/400\n",
            "12/12 [==============================] - 39s 3s/step - loss: 0.6712 - accuracy: 0.5845 - val_loss: 0.6393 - val_accuracy: 0.6464\n",
            "Epoch 3/400\n",
            "12/12 [==============================] - 39s 3s/step - loss: 0.6258 - accuracy: 0.6674 - val_loss: 0.5930 - val_accuracy: 0.7048\n",
            "Epoch 4/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.6064 - accuracy: 0.6872 - val_loss: 0.5789 - val_accuracy: 0.7224\n",
            "Epoch 5/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.5994 - accuracy: 0.6999 - val_loss: 0.5933 - val_accuracy: 0.6992\n",
            "Epoch 6/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5953 - accuracy: 0.7031 - val_loss: 0.6095 - val_accuracy: 0.7328\n",
            "Epoch 7/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.6098 - accuracy: 0.6919 - val_loss: 0.5984 - val_accuracy: 0.7168\n",
            "Epoch 8/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5899 - accuracy: 0.7086 - val_loss: 0.6442 - val_accuracy: 0.6872\n",
            "Epoch 9/400\n",
            "12/12 [==============================] - 31s 3s/step - loss: 0.6344 - accuracy: 0.6611 - val_loss: 0.6888 - val_accuracy: 0.5200\n",
            "Epoch 10/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.6933 - accuracy: 0.5261 - val_loss: 0.6395 - val_accuracy: 0.6224\n",
            "Epoch 11/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.6048 - accuracy: 0.6803 - val_loss: 0.6502 - val_accuracy: 0.7112\n",
            "Epoch 12/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5711 - accuracy: 0.7224 - val_loss: 0.5795 - val_accuracy: 0.7128\n",
            "Epoch 13/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5525 - accuracy: 0.7262 - val_loss: 0.6759 - val_accuracy: 0.6904\n",
            "Epoch 14/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.5429 - accuracy: 0.7324 - val_loss: 0.6313 - val_accuracy: 0.7152\n",
            "Epoch 15/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5394 - accuracy: 0.7355 - val_loss: 0.5978 - val_accuracy: 0.7376\n",
            "Epoch 16/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5310 - accuracy: 0.7400 - val_loss: 0.6281 - val_accuracy: 0.7448\n",
            "Epoch 17/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5205 - accuracy: 0.7479 - val_loss: 0.5882 - val_accuracy: 0.7520\n",
            "Epoch 18/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.5167 - accuracy: 0.7508 - val_loss: 0.6617 - val_accuracy: 0.7472\n",
            "Epoch 19/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.5170 - accuracy: 0.7546 - val_loss: 0.5658 - val_accuracy: 0.7560\n",
            "Epoch 20/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.5250 - accuracy: 0.7502 - val_loss: 0.5488 - val_accuracy: 0.7656\n",
            "Epoch 21/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.5093 - accuracy: 0.7603 - val_loss: 0.6062 - val_accuracy: 0.7608\n",
            "Epoch 22/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.5011 - accuracy: 0.7620 - val_loss: 0.5954 - val_accuracy: 0.7680\n",
            "Epoch 23/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4946 - accuracy: 0.7696 - val_loss: 0.5328 - val_accuracy: 0.7808\n",
            "Epoch 24/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4925 - accuracy: 0.7663 - val_loss: 0.5903 - val_accuracy: 0.7720\n",
            "Epoch 25/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4961 - accuracy: 0.7646 - val_loss: 0.6230 - val_accuracy: 0.7568\n",
            "Epoch 26/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.4976 - accuracy: 0.7636 - val_loss: 0.5785 - val_accuracy: 0.7688\n",
            "Epoch 27/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4768 - accuracy: 0.7782 - val_loss: 0.5722 - val_accuracy: 0.7712\n",
            "Epoch 28/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4727 - accuracy: 0.7805 - val_loss: 0.5480 - val_accuracy: 0.7864\n",
            "Epoch 29/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4754 - accuracy: 0.7789 - val_loss: 0.5760 - val_accuracy: 0.7808\n",
            "Epoch 30/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4664 - accuracy: 0.7853 - val_loss: 0.5118 - val_accuracy: 0.7920\n",
            "Epoch 31/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4601 - accuracy: 0.7881 - val_loss: 0.5538 - val_accuracy: 0.7824\n",
            "Epoch 32/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4579 - accuracy: 0.7895 - val_loss: 0.5365 - val_accuracy: 0.7840\n",
            "Epoch 33/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4504 - accuracy: 0.7962 - val_loss: 0.5229 - val_accuracy: 0.7936\n",
            "Epoch 34/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4541 - accuracy: 0.7909 - val_loss: 0.5114 - val_accuracy: 0.7920\n",
            "Epoch 35/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4427 - accuracy: 0.7983 - val_loss: 0.5327 - val_accuracy: 0.7888\n",
            "Epoch 36/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4440 - accuracy: 0.7993 - val_loss: 0.6439 - val_accuracy: 0.7688\n",
            "Epoch 37/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4419 - accuracy: 0.8002 - val_loss: 0.4982 - val_accuracy: 0.7984\n",
            "Epoch 38/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4381 - accuracy: 0.7973 - val_loss: 0.4942 - val_accuracy: 0.8096\n",
            "Epoch 39/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4372 - accuracy: 0.7995 - val_loss: 0.5351 - val_accuracy: 0.7928\n",
            "Epoch 40/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4326 - accuracy: 0.8048 - val_loss: 0.4695 - val_accuracy: 0.8080\n",
            "Epoch 41/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4263 - accuracy: 0.8077 - val_loss: 0.4914 - val_accuracy: 0.8048\n",
            "Epoch 42/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4153 - accuracy: 0.8132 - val_loss: 0.5074 - val_accuracy: 0.8112\n",
            "Epoch 43/400\n",
            "12/12 [==============================] - 37s 3s/step - loss: 0.4127 - accuracy: 0.8133 - val_loss: 0.4588 - val_accuracy: 0.8168\n",
            "Epoch 44/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4129 - accuracy: 0.8155 - val_loss: 0.4766 - val_accuracy: 0.8144\n",
            "Epoch 45/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4082 - accuracy: 0.8157 - val_loss: 0.4412 - val_accuracy: 0.8232\n",
            "Epoch 46/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4055 - accuracy: 0.8181 - val_loss: 0.4523 - val_accuracy: 0.8304\n",
            "Epoch 47/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.4248 - accuracy: 0.8115 - val_loss: 0.4081 - val_accuracy: 0.8368\n",
            "Epoch 48/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.4080 - accuracy: 0.8163 - val_loss: 0.4801 - val_accuracy: 0.8112\n",
            "Epoch 49/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3995 - accuracy: 0.8215 - val_loss: 0.5098 - val_accuracy: 0.8176\n",
            "Epoch 50/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4013 - accuracy: 0.8215 - val_loss: 0.4804 - val_accuracy: 0.8096\n",
            "Epoch 51/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3946 - accuracy: 0.8211 - val_loss: 0.4142 - val_accuracy: 0.8440\n",
            "Epoch 52/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3978 - accuracy: 0.8208 - val_loss: 0.5286 - val_accuracy: 0.8144\n",
            "Epoch 53/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4014 - accuracy: 0.8213 - val_loss: 0.5042 - val_accuracy: 0.8160\n",
            "Epoch 54/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.4118 - accuracy: 0.8158 - val_loss: 0.4283 - val_accuracy: 0.8344\n",
            "Epoch 55/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3951 - accuracy: 0.8235 - val_loss: 0.4777 - val_accuracy: 0.8232\n",
            "Epoch 56/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3930 - accuracy: 0.8258 - val_loss: 0.4355 - val_accuracy: 0.8368\n",
            "Epoch 57/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3851 - accuracy: 0.8269 - val_loss: 0.4669 - val_accuracy: 0.8320\n",
            "Epoch 58/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3774 - accuracy: 0.8316 - val_loss: 0.4871 - val_accuracy: 0.8152\n",
            "Epoch 59/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3799 - accuracy: 0.8301 - val_loss: 0.4336 - val_accuracy: 0.8392\n",
            "Epoch 60/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3937 - accuracy: 0.8242 - val_loss: 0.4258 - val_accuracy: 0.8416\n",
            "Epoch 61/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3747 - accuracy: 0.8346 - val_loss: 0.4236 - val_accuracy: 0.8400\n",
            "Epoch 62/400\n",
            "12/12 [==============================] - 37s 3s/step - loss: 0.3760 - accuracy: 0.8321 - val_loss: 0.3816 - val_accuracy: 0.8472\n",
            "Epoch 63/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3780 - accuracy: 0.8335 - val_loss: 0.4694 - val_accuracy: 0.8320\n",
            "Epoch 64/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3709 - accuracy: 0.8354 - val_loss: 0.4555 - val_accuracy: 0.8344\n",
            "Epoch 65/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3758 - accuracy: 0.8325 - val_loss: 0.4409 - val_accuracy: 0.8376\n",
            "Epoch 66/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3712 - accuracy: 0.8381 - val_loss: 0.4302 - val_accuracy: 0.8504\n",
            "Epoch 67/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3637 - accuracy: 0.8384 - val_loss: 0.4108 - val_accuracy: 0.8480\n",
            "Epoch 68/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3653 - accuracy: 0.8399 - val_loss: 0.4358 - val_accuracy: 0.8512\n",
            "Epoch 69/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3690 - accuracy: 0.8339 - val_loss: 0.4322 - val_accuracy: 0.8440\n",
            "Epoch 70/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3611 - accuracy: 0.8420 - val_loss: 0.4305 - val_accuracy: 0.8520\n",
            "Epoch 71/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3724 - accuracy: 0.8350 - val_loss: 0.4269 - val_accuracy: 0.8496\n",
            "Epoch 72/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3866 - accuracy: 0.8276 - val_loss: 0.4713 - val_accuracy: 0.8240\n",
            "Epoch 73/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3751 - accuracy: 0.8341 - val_loss: 0.4211 - val_accuracy: 0.8416\n",
            "Epoch 74/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3631 - accuracy: 0.8427 - val_loss: 0.3956 - val_accuracy: 0.8536\n",
            "Epoch 75/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3697 - accuracy: 0.8364 - val_loss: 0.4549 - val_accuracy: 0.8360\n",
            "Epoch 76/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3674 - accuracy: 0.8363 - val_loss: 0.4028 - val_accuracy: 0.8448\n",
            "Epoch 77/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3593 - accuracy: 0.8416 - val_loss: 0.4279 - val_accuracy: 0.8488\n",
            "Epoch 78/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3533 - accuracy: 0.8450 - val_loss: 0.4051 - val_accuracy: 0.8496\n",
            "Epoch 79/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3583 - accuracy: 0.8441 - val_loss: 0.4036 - val_accuracy: 0.8448\n",
            "Epoch 80/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3558 - accuracy: 0.8443 - val_loss: 0.4227 - val_accuracy: 0.8528\n",
            "Epoch 81/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.3494 - accuracy: 0.8463 - val_loss: 0.3738 - val_accuracy: 0.8520\n",
            "Epoch 82/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3507 - accuracy: 0.8471 - val_loss: 0.4338 - val_accuracy: 0.8520\n",
            "Epoch 83/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3482 - accuracy: 0.8475 - val_loss: 0.3815 - val_accuracy: 0.8504\n",
            "Epoch 84/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3504 - accuracy: 0.8440 - val_loss: 0.4319 - val_accuracy: 0.8472\n",
            "Epoch 85/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3532 - accuracy: 0.8436 - val_loss: 0.3893 - val_accuracy: 0.8600\n",
            "Epoch 86/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3535 - accuracy: 0.8447 - val_loss: 0.3975 - val_accuracy: 0.8552\n",
            "Epoch 87/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3455 - accuracy: 0.8502 - val_loss: 0.3848 - val_accuracy: 0.8560\n",
            "Epoch 88/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3445 - accuracy: 0.8507 - val_loss: 0.3826 - val_accuracy: 0.8568\n",
            "Epoch 89/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3448 - accuracy: 0.8505 - val_loss: 0.3918 - val_accuracy: 0.8576\n",
            "Epoch 90/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3447 - accuracy: 0.8495 - val_loss: 0.3801 - val_accuracy: 0.8560\n",
            "Epoch 91/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3499 - accuracy: 0.8471 - val_loss: 0.4161 - val_accuracy: 0.8584\n",
            "Epoch 92/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3464 - accuracy: 0.8492 - val_loss: 0.3826 - val_accuracy: 0.8608\n",
            "Epoch 93/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3476 - accuracy: 0.8489 - val_loss: 0.4209 - val_accuracy: 0.8568\n",
            "Epoch 94/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3463 - accuracy: 0.8463 - val_loss: 0.3832 - val_accuracy: 0.8536\n",
            "Epoch 95/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3441 - accuracy: 0.8478 - val_loss: 0.3810 - val_accuracy: 0.8528\n",
            "Epoch 96/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3403 - accuracy: 0.8498 - val_loss: 0.4022 - val_accuracy: 0.8584\n",
            "Epoch 97/400\n",
            "12/12 [==============================] - 37s 3s/step - loss: 0.3383 - accuracy: 0.8526 - val_loss: 0.3561 - val_accuracy: 0.8624\n",
            "Epoch 98/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3370 - accuracy: 0.8511 - val_loss: 0.4035 - val_accuracy: 0.8536\n",
            "Epoch 99/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3369 - accuracy: 0.8548 - val_loss: 0.3793 - val_accuracy: 0.8624\n",
            "Epoch 100/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3396 - accuracy: 0.8511 - val_loss: 0.3959 - val_accuracy: 0.8600\n",
            "Epoch 101/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3372 - accuracy: 0.8539 - val_loss: 0.4228 - val_accuracy: 0.8560\n",
            "Epoch 102/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3370 - accuracy: 0.8543 - val_loss: 0.3670 - val_accuracy: 0.8544\n",
            "Epoch 103/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3413 - accuracy: 0.8500 - val_loss: 0.3697 - val_accuracy: 0.8624\n",
            "Epoch 104/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3374 - accuracy: 0.8542 - val_loss: 0.3776 - val_accuracy: 0.8624\n",
            "Epoch 105/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3367 - accuracy: 0.8555 - val_loss: 0.3670 - val_accuracy: 0.8680\n",
            "Epoch 106/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3308 - accuracy: 0.8571 - val_loss: 0.3670 - val_accuracy: 0.8616\n",
            "Epoch 107/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3302 - accuracy: 0.8577 - val_loss: 0.3908 - val_accuracy: 0.8624\n",
            "Epoch 108/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3404 - accuracy: 0.8530 - val_loss: 0.4090 - val_accuracy: 0.8616\n",
            "Epoch 109/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3302 - accuracy: 0.8570 - val_loss: 0.3772 - val_accuracy: 0.8624\n",
            "Epoch 110/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3333 - accuracy: 0.8538 - val_loss: 0.3842 - val_accuracy: 0.8504\n",
            "Epoch 111/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3384 - accuracy: 0.8525 - val_loss: 0.3900 - val_accuracy: 0.8576\n",
            "Epoch 112/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3326 - accuracy: 0.8533 - val_loss: 0.3738 - val_accuracy: 0.8680\n",
            "Epoch 113/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3285 - accuracy: 0.8601 - val_loss: 0.3779 - val_accuracy: 0.8608\n",
            "Epoch 114/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3285 - accuracy: 0.8573 - val_loss: 0.3726 - val_accuracy: 0.8560\n",
            "Epoch 115/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3242 - accuracy: 0.8594 - val_loss: 0.3575 - val_accuracy: 0.8648\n",
            "Epoch 116/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3221 - accuracy: 0.8617 - val_loss: 0.3747 - val_accuracy: 0.8592\n",
            "Epoch 117/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3291 - accuracy: 0.8567 - val_loss: 0.3841 - val_accuracy: 0.8536\n",
            "Epoch 118/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3250 - accuracy: 0.8599 - val_loss: 0.3626 - val_accuracy: 0.8640\n",
            "Epoch 119/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3245 - accuracy: 0.8589 - val_loss: 0.3831 - val_accuracy: 0.8600\n",
            "Epoch 120/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3272 - accuracy: 0.8567 - val_loss: 0.3650 - val_accuracy: 0.8632\n",
            "Epoch 121/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3267 - accuracy: 0.8579 - val_loss: 0.3832 - val_accuracy: 0.8616\n",
            "Epoch 122/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3287 - accuracy: 0.8539 - val_loss: 0.3628 - val_accuracy: 0.8608\n",
            "Epoch 123/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3245 - accuracy: 0.8588 - val_loss: 0.3718 - val_accuracy: 0.8648\n",
            "Epoch 124/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3278 - accuracy: 0.8573 - val_loss: 0.4019 - val_accuracy: 0.8616\n",
            "Epoch 125/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3215 - accuracy: 0.8627 - val_loss: 0.3757 - val_accuracy: 0.8664\n",
            "Epoch 126/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3236 - accuracy: 0.8593 - val_loss: 0.3800 - val_accuracy: 0.8664\n",
            "Epoch 127/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.3282 - accuracy: 0.8581 - val_loss: 0.3477 - val_accuracy: 0.8584\n",
            "Epoch 128/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3246 - accuracy: 0.8599 - val_loss: 0.3711 - val_accuracy: 0.8632\n",
            "Epoch 129/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3197 - accuracy: 0.8600 - val_loss: 0.3751 - val_accuracy: 0.8704\n",
            "Epoch 130/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3127 - accuracy: 0.8632 - val_loss: 0.3711 - val_accuracy: 0.8640\n",
            "Epoch 131/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3164 - accuracy: 0.8620 - val_loss: 0.3749 - val_accuracy: 0.8672\n",
            "Epoch 132/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3117 - accuracy: 0.8665 - val_loss: 0.3734 - val_accuracy: 0.8672\n",
            "Epoch 133/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.3147 - accuracy: 0.8632 - val_loss: 0.3425 - val_accuracy: 0.8696\n",
            "Epoch 134/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3194 - accuracy: 0.8632 - val_loss: 0.3466 - val_accuracy: 0.8728\n",
            "Epoch 135/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3133 - accuracy: 0.8662 - val_loss: 0.3721 - val_accuracy: 0.8664\n",
            "Epoch 136/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3150 - accuracy: 0.8662 - val_loss: 0.3554 - val_accuracy: 0.8672\n",
            "Epoch 137/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3141 - accuracy: 0.8635 - val_loss: 0.3635 - val_accuracy: 0.8640\n",
            "Epoch 138/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3138 - accuracy: 0.8640 - val_loss: 0.3750 - val_accuracy: 0.8648\n",
            "Epoch 139/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3061 - accuracy: 0.8680 - val_loss: 0.3562 - val_accuracy: 0.8688\n",
            "Epoch 140/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.3141 - accuracy: 0.8621 - val_loss: 0.3367 - val_accuracy: 0.8760\n",
            "Epoch 141/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3116 - accuracy: 0.8650 - val_loss: 0.3634 - val_accuracy: 0.8640\n",
            "Epoch 142/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3077 - accuracy: 0.8669 - val_loss: 0.3686 - val_accuracy: 0.8712\n",
            "Epoch 143/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3062 - accuracy: 0.8696 - val_loss: 0.3674 - val_accuracy: 0.8728\n",
            "Epoch 144/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3120 - accuracy: 0.8638 - val_loss: 0.3465 - val_accuracy: 0.8680\n",
            "Epoch 145/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3070 - accuracy: 0.8680 - val_loss: 0.3731 - val_accuracy: 0.8656\n",
            "Epoch 146/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3287 - accuracy: 0.8579 - val_loss: 0.3727 - val_accuracy: 0.8688\n",
            "Epoch 147/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3245 - accuracy: 0.8614 - val_loss: 0.3417 - val_accuracy: 0.8672\n",
            "Epoch 148/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3099 - accuracy: 0.8666 - val_loss: 0.3611 - val_accuracy: 0.8720\n",
            "Epoch 149/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3056 - accuracy: 0.8683 - val_loss: 0.3445 - val_accuracy: 0.8728\n",
            "Epoch 150/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3034 - accuracy: 0.8681 - val_loss: 0.3389 - val_accuracy: 0.8752\n",
            "Epoch 151/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3031 - accuracy: 0.8722 - val_loss: 0.3587 - val_accuracy: 0.8688\n",
            "Epoch 152/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3038 - accuracy: 0.8689 - val_loss: 0.3654 - val_accuracy: 0.8688\n",
            "Epoch 153/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3062 - accuracy: 0.8693 - val_loss: 0.3791 - val_accuracy: 0.8720\n",
            "Epoch 154/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.3104 - accuracy: 0.8670 - val_loss: 0.3309 - val_accuracy: 0.8696\n",
            "Epoch 155/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3159 - accuracy: 0.8661 - val_loss: 0.4107 - val_accuracy: 0.8568\n",
            "Epoch 156/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3064 - accuracy: 0.8663 - val_loss: 0.3646 - val_accuracy: 0.8688\n",
            "Epoch 157/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3012 - accuracy: 0.8722 - val_loss: 0.3457 - val_accuracy: 0.8760\n",
            "Epoch 158/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2976 - accuracy: 0.8730 - val_loss: 0.3579 - val_accuracy: 0.8744\n",
            "Epoch 159/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3008 - accuracy: 0.8709 - val_loss: 0.3430 - val_accuracy: 0.8688\n",
            "Epoch 160/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.3048 - accuracy: 0.8690 - val_loss: 0.3855 - val_accuracy: 0.8632\n",
            "Epoch 161/400\n",
            "12/12 [==============================] - 38s 3s/step - loss: 0.3029 - accuracy: 0.8723 - val_loss: 0.3266 - val_accuracy: 0.8680\n",
            "Epoch 162/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.3019 - accuracy: 0.8716 - val_loss: 0.3483 - val_accuracy: 0.8704\n",
            "Epoch 163/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3058 - accuracy: 0.8691 - val_loss: 0.3477 - val_accuracy: 0.8744\n",
            "Epoch 164/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2952 - accuracy: 0.8734 - val_loss: 0.3478 - val_accuracy: 0.8696\n",
            "Epoch 165/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2984 - accuracy: 0.8702 - val_loss: 0.3429 - val_accuracy: 0.8776\n",
            "Epoch 166/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2993 - accuracy: 0.8707 - val_loss: 0.3804 - val_accuracy: 0.8656\n",
            "Epoch 167/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.3031 - accuracy: 0.8711 - val_loss: 0.3408 - val_accuracy: 0.8720\n",
            "Epoch 168/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2958 - accuracy: 0.8734 - val_loss: 0.3574 - val_accuracy: 0.8728\n",
            "Epoch 169/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2957 - accuracy: 0.8751 - val_loss: 0.3474 - val_accuracy: 0.8776\n",
            "Epoch 170/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2975 - accuracy: 0.8709 - val_loss: 0.3454 - val_accuracy: 0.8728\n",
            "Epoch 171/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2924 - accuracy: 0.8767 - val_loss: 0.3360 - val_accuracy: 0.8776\n",
            "Epoch 172/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2871 - accuracy: 0.8778 - val_loss: 0.3529 - val_accuracy: 0.8720\n",
            "Epoch 173/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2922 - accuracy: 0.8741 - val_loss: 0.3363 - val_accuracy: 0.8728\n",
            "Epoch 174/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2912 - accuracy: 0.8753 - val_loss: 0.3494 - val_accuracy: 0.8760\n",
            "Epoch 175/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2922 - accuracy: 0.8748 - val_loss: 0.3737 - val_accuracy: 0.8680\n",
            "Epoch 176/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2919 - accuracy: 0.8743 - val_loss: 0.3556 - val_accuracy: 0.8720\n",
            "Epoch 177/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2875 - accuracy: 0.8761 - val_loss: 0.3398 - val_accuracy: 0.8800\n",
            "Epoch 178/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2859 - accuracy: 0.8776 - val_loss: 0.3422 - val_accuracy: 0.8768\n",
            "Epoch 179/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2892 - accuracy: 0.8773 - val_loss: 0.3410 - val_accuracy: 0.8712\n",
            "Epoch 180/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2893 - accuracy: 0.8760 - val_loss: 0.3314 - val_accuracy: 0.8736\n",
            "Epoch 181/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2917 - accuracy: 0.8744 - val_loss: 0.3634 - val_accuracy: 0.8704\n",
            "Epoch 182/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2939 - accuracy: 0.8747 - val_loss: 0.3444 - val_accuracy: 0.8752\n",
            "Epoch 183/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2939 - accuracy: 0.8749 - val_loss: 0.3460 - val_accuracy: 0.8744\n",
            "Epoch 184/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2909 - accuracy: 0.8755 - val_loss: 0.3359 - val_accuracy: 0.8720\n",
            "Epoch 185/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2843 - accuracy: 0.8782 - val_loss: 0.3422 - val_accuracy: 0.8728\n",
            "Epoch 186/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2852 - accuracy: 0.8774 - val_loss: 0.3279 - val_accuracy: 0.8784\n",
            "Epoch 187/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2885 - accuracy: 0.8765 - val_loss: 0.3456 - val_accuracy: 0.8736\n",
            "Epoch 188/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2826 - accuracy: 0.8793 - val_loss: 0.3315 - val_accuracy: 0.8792\n",
            "Epoch 189/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2849 - accuracy: 0.8795 - val_loss: 0.3723 - val_accuracy: 0.8720\n",
            "Epoch 190/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2921 - accuracy: 0.8766 - val_loss: 0.3385 - val_accuracy: 0.8696\n",
            "Epoch 191/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2892 - accuracy: 0.8767 - val_loss: 0.3515 - val_accuracy: 0.8736\n",
            "Epoch 192/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2838 - accuracy: 0.8792 - val_loss: 0.3593 - val_accuracy: 0.8728\n",
            "Epoch 193/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2908 - accuracy: 0.8757 - val_loss: 0.3769 - val_accuracy: 0.8736\n",
            "Epoch 194/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2829 - accuracy: 0.8795 - val_loss: 0.3629 - val_accuracy: 0.8704\n",
            "Epoch 195/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2886 - accuracy: 0.8784 - val_loss: 0.3291 - val_accuracy: 0.8760\n",
            "Epoch 196/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2816 - accuracy: 0.8782 - val_loss: 0.3954 - val_accuracy: 0.8720\n",
            "Epoch 197/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2839 - accuracy: 0.8811 - val_loss: 0.3437 - val_accuracy: 0.8744\n",
            "Epoch 198/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2871 - accuracy: 0.8770 - val_loss: 0.3291 - val_accuracy: 0.8744\n",
            "Epoch 199/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2778 - accuracy: 0.8792 - val_loss: 0.3500 - val_accuracy: 0.8680\n",
            "Epoch 200/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2814 - accuracy: 0.8798 - val_loss: 0.3884 - val_accuracy: 0.8760\n",
            "Epoch 201/400\n",
            "12/12 [==============================] - 37s 3s/step - loss: 0.2784 - accuracy: 0.8829 - val_loss: 0.3232 - val_accuracy: 0.8744\n",
            "Epoch 202/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2745 - accuracy: 0.8835 - val_loss: 0.3475 - val_accuracy: 0.8760\n",
            "Epoch 203/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2806 - accuracy: 0.8780 - val_loss: 0.3523 - val_accuracy: 0.8736\n",
            "Epoch 204/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2813 - accuracy: 0.8805 - val_loss: 0.3345 - val_accuracy: 0.8728\n",
            "Epoch 205/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2752 - accuracy: 0.8839 - val_loss: 0.3701 - val_accuracy: 0.8752\n",
            "Epoch 206/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2748 - accuracy: 0.8843 - val_loss: 0.3815 - val_accuracy: 0.8768\n",
            "Epoch 207/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2789 - accuracy: 0.8805 - val_loss: 0.3394 - val_accuracy: 0.8704\n",
            "Epoch 208/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2773 - accuracy: 0.8807 - val_loss: 0.3523 - val_accuracy: 0.8760\n",
            "Epoch 209/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2786 - accuracy: 0.8816 - val_loss: 0.3406 - val_accuracy: 0.8808\n",
            "Epoch 210/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2731 - accuracy: 0.8851 - val_loss: 0.3537 - val_accuracy: 0.8776\n",
            "Epoch 211/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2737 - accuracy: 0.8820 - val_loss: 0.3462 - val_accuracy: 0.8784\n",
            "Epoch 212/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2737 - accuracy: 0.8840 - val_loss: 0.3431 - val_accuracy: 0.8792\n",
            "Epoch 213/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2760 - accuracy: 0.8824 - val_loss: 0.3603 - val_accuracy: 0.8728\n",
            "Epoch 214/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2773 - accuracy: 0.8793 - val_loss: 0.3316 - val_accuracy: 0.8800\n",
            "Epoch 215/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2765 - accuracy: 0.8846 - val_loss: 0.3403 - val_accuracy: 0.8792\n",
            "Epoch 216/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2736 - accuracy: 0.8854 - val_loss: 0.3765 - val_accuracy: 0.8768\n",
            "Epoch 217/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2687 - accuracy: 0.8883 - val_loss: 0.3555 - val_accuracy: 0.8784\n",
            "Epoch 218/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2725 - accuracy: 0.8812 - val_loss: 0.3647 - val_accuracy: 0.8744\n",
            "Epoch 219/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2764 - accuracy: 0.8818 - val_loss: 0.3465 - val_accuracy: 0.8744\n",
            "Epoch 220/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2715 - accuracy: 0.8849 - val_loss: 0.3469 - val_accuracy: 0.8760\n",
            "Epoch 221/400\n",
            "12/12 [==============================] - 31s 3s/step - loss: 0.2722 - accuracy: 0.8816 - val_loss: 0.3466 - val_accuracy: 0.8784\n",
            "Epoch 222/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2641 - accuracy: 0.8867 - val_loss: 0.3569 - val_accuracy: 0.8776\n",
            "Epoch 223/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2675 - accuracy: 0.8870 - val_loss: 0.3725 - val_accuracy: 0.8800\n",
            "Epoch 224/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2670 - accuracy: 0.8860 - val_loss: 0.3504 - val_accuracy: 0.8784\n",
            "Epoch 225/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2675 - accuracy: 0.8865 - val_loss: 0.3601 - val_accuracy: 0.8792\n",
            "Epoch 226/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2698 - accuracy: 0.8828 - val_loss: 0.3401 - val_accuracy: 0.8776\n",
            "Epoch 227/400\n",
            "12/12 [==============================] - 31s 3s/step - loss: 0.2657 - accuracy: 0.8874 - val_loss: 0.3458 - val_accuracy: 0.8784\n",
            "Epoch 228/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2644 - accuracy: 0.8876 - val_loss: 0.3412 - val_accuracy: 0.8752\n",
            "Epoch 229/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2700 - accuracy: 0.8861 - val_loss: 0.3449 - val_accuracy: 0.8768\n",
            "Epoch 230/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2673 - accuracy: 0.8861 - val_loss: 0.3658 - val_accuracy: 0.8680\n",
            "Epoch 231/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2754 - accuracy: 0.8811 - val_loss: 0.3325 - val_accuracy: 0.8816\n",
            "Epoch 232/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2715 - accuracy: 0.8859 - val_loss: 0.3505 - val_accuracy: 0.8768\n",
            "Epoch 233/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2664 - accuracy: 0.8864 - val_loss: 0.3487 - val_accuracy: 0.8736\n",
            "Epoch 234/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2661 - accuracy: 0.8856 - val_loss: 0.3446 - val_accuracy: 0.8776\n",
            "Epoch 235/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2669 - accuracy: 0.8859 - val_loss: 0.3466 - val_accuracy: 0.8736\n",
            "Epoch 236/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2640 - accuracy: 0.8876 - val_loss: 0.3358 - val_accuracy: 0.8752\n",
            "Epoch 237/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2642 - accuracy: 0.8893 - val_loss: 0.3603 - val_accuracy: 0.8728\n",
            "Epoch 238/400\n",
            "12/12 [==============================] - 28s 2s/step - loss: 0.2613 - accuracy: 0.8884 - val_loss: 0.3756 - val_accuracy: 0.8792\n",
            "Epoch 239/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2655 - accuracy: 0.8883 - val_loss: 0.3396 - val_accuracy: 0.8800\n",
            "Epoch 240/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2586 - accuracy: 0.8915 - val_loss: 0.3537 - val_accuracy: 0.8720\n",
            "Epoch 241/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2647 - accuracy: 0.8887 - val_loss: 0.3886 - val_accuracy: 0.8792\n",
            "Epoch 242/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2631 - accuracy: 0.8884 - val_loss: 0.3441 - val_accuracy: 0.8728\n",
            "Epoch 243/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2570 - accuracy: 0.8913 - val_loss: 0.3470 - val_accuracy: 0.8720\n",
            "Epoch 244/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2608 - accuracy: 0.8879 - val_loss: 0.3426 - val_accuracy: 0.8784\n",
            "Epoch 245/400\n",
            "12/12 [==============================] - 28s 2s/step - loss: 0.2596 - accuracy: 0.8889 - val_loss: 0.3573 - val_accuracy: 0.8760\n",
            "Epoch 246/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2590 - accuracy: 0.8890 - val_loss: 0.3437 - val_accuracy: 0.8808\n",
            "Epoch 247/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2587 - accuracy: 0.8904 - val_loss: 0.3636 - val_accuracy: 0.8688\n",
            "Epoch 248/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2604 - accuracy: 0.8895 - val_loss: 0.3365 - val_accuracy: 0.8792\n",
            "Epoch 249/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2639 - accuracy: 0.8882 - val_loss: 0.3411 - val_accuracy: 0.8728\n",
            "Epoch 250/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2642 - accuracy: 0.8880 - val_loss: 0.3727 - val_accuracy: 0.8728\n",
            "Epoch 251/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2675 - accuracy: 0.8877 - val_loss: 0.3689 - val_accuracy: 0.8728\n",
            "Epoch 252/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2657 - accuracy: 0.8878 - val_loss: 0.3463 - val_accuracy: 0.8728\n",
            "Epoch 253/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2571 - accuracy: 0.8924 - val_loss: 0.3348 - val_accuracy: 0.8856\n",
            "Epoch 254/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2548 - accuracy: 0.8934 - val_loss: 0.3527 - val_accuracy: 0.8776\n",
            "Epoch 255/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2618 - accuracy: 0.8890 - val_loss: 0.3581 - val_accuracy: 0.8744\n",
            "Epoch 256/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2576 - accuracy: 0.8913 - val_loss: 0.3336 - val_accuracy: 0.8728\n",
            "Epoch 257/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2539 - accuracy: 0.8923 - val_loss: 0.3439 - val_accuracy: 0.8768\n",
            "Epoch 258/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2610 - accuracy: 0.8915 - val_loss: 0.3683 - val_accuracy: 0.8768\n",
            "Epoch 259/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2533 - accuracy: 0.8928 - val_loss: 0.3425 - val_accuracy: 0.8728\n",
            "Epoch 260/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2489 - accuracy: 0.8960 - val_loss: 0.3398 - val_accuracy: 0.8768\n",
            "Epoch 261/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2545 - accuracy: 0.8919 - val_loss: 0.3704 - val_accuracy: 0.8728\n",
            "Epoch 262/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2518 - accuracy: 0.8936 - val_loss: 0.3468 - val_accuracy: 0.8800\n",
            "Epoch 263/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2494 - accuracy: 0.8917 - val_loss: 0.3576 - val_accuracy: 0.8816\n",
            "Epoch 264/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2587 - accuracy: 0.8917 - val_loss: 0.3619 - val_accuracy: 0.8736\n",
            "Epoch 265/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2534 - accuracy: 0.8913 - val_loss: 0.3650 - val_accuracy: 0.8728\n",
            "Epoch 266/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2496 - accuracy: 0.8949 - val_loss: 0.3427 - val_accuracy: 0.8776\n",
            "Epoch 267/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2529 - accuracy: 0.8929 - val_loss: 0.3549 - val_accuracy: 0.8736\n",
            "Epoch 268/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2490 - accuracy: 0.8962 - val_loss: 0.3616 - val_accuracy: 0.8744\n",
            "Epoch 269/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2603 - accuracy: 0.8900 - val_loss: 0.3836 - val_accuracy: 0.8800\n",
            "Epoch 270/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2550 - accuracy: 0.8913 - val_loss: 0.3616 - val_accuracy: 0.8800\n",
            "Epoch 271/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2477 - accuracy: 0.8965 - val_loss: 0.3500 - val_accuracy: 0.8744\n",
            "Epoch 272/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2499 - accuracy: 0.8933 - val_loss: 0.3420 - val_accuracy: 0.8752\n",
            "Epoch 273/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2487 - accuracy: 0.8961 - val_loss: 0.3622 - val_accuracy: 0.8760\n",
            "Epoch 274/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2467 - accuracy: 0.8963 - val_loss: 0.3447 - val_accuracy: 0.8768\n",
            "Epoch 275/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2463 - accuracy: 0.8952 - val_loss: 0.3432 - val_accuracy: 0.8792\n",
            "Epoch 276/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2496 - accuracy: 0.8949 - val_loss: 0.3341 - val_accuracy: 0.8752\n",
            "Epoch 277/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2537 - accuracy: 0.8915 - val_loss: 0.3463 - val_accuracy: 0.8736\n",
            "Epoch 278/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2513 - accuracy: 0.8929 - val_loss: 0.3450 - val_accuracy: 0.8712\n",
            "Epoch 279/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2483 - accuracy: 0.8927 - val_loss: 0.3933 - val_accuracy: 0.8752\n",
            "Epoch 280/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2476 - accuracy: 0.8947 - val_loss: 0.3690 - val_accuracy: 0.8848\n",
            "Epoch 281/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2431 - accuracy: 0.8985 - val_loss: 0.3534 - val_accuracy: 0.8784\n",
            "Epoch 282/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2461 - accuracy: 0.8968 - val_loss: 0.3291 - val_accuracy: 0.8800\n",
            "Epoch 283/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2469 - accuracy: 0.8955 - val_loss: 0.3621 - val_accuracy: 0.8776\n",
            "Epoch 284/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2431 - accuracy: 0.8993 - val_loss: 0.3365 - val_accuracy: 0.8824\n",
            "Epoch 285/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2414 - accuracy: 0.9003 - val_loss: 0.3616 - val_accuracy: 0.8760\n",
            "Epoch 286/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2427 - accuracy: 0.8985 - val_loss: 0.3519 - val_accuracy: 0.8784\n",
            "Epoch 287/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2426 - accuracy: 0.8974 - val_loss: 0.3585 - val_accuracy: 0.8736\n",
            "Epoch 288/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2418 - accuracy: 0.8981 - val_loss: 0.3428 - val_accuracy: 0.8792\n",
            "Epoch 289/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2454 - accuracy: 0.8944 - val_loss: 0.3836 - val_accuracy: 0.8760\n",
            "Epoch 290/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2520 - accuracy: 0.8968 - val_loss: 0.3824 - val_accuracy: 0.8736\n",
            "Epoch 291/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2552 - accuracy: 0.8921 - val_loss: 0.3253 - val_accuracy: 0.8776\n",
            "Epoch 292/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2538 - accuracy: 0.8937 - val_loss: 0.3485 - val_accuracy: 0.8712\n",
            "Epoch 293/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2394 - accuracy: 0.8983 - val_loss: 0.3599 - val_accuracy: 0.8776\n",
            "Epoch 294/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2421 - accuracy: 0.8971 - val_loss: 0.3463 - val_accuracy: 0.8760\n",
            "Epoch 295/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2394 - accuracy: 0.8990 - val_loss: 0.3680 - val_accuracy: 0.8768\n",
            "Epoch 296/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2421 - accuracy: 0.8973 - val_loss: 0.3730 - val_accuracy: 0.8744\n",
            "Epoch 297/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2404 - accuracy: 0.8988 - val_loss: 0.3377 - val_accuracy: 0.8808\n",
            "Epoch 298/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2399 - accuracy: 0.9004 - val_loss: 0.3415 - val_accuracy: 0.8728\n",
            "Epoch 299/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2361 - accuracy: 0.9020 - val_loss: 0.3546 - val_accuracy: 0.8800\n",
            "Epoch 300/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2366 - accuracy: 0.9012 - val_loss: 0.3439 - val_accuracy: 0.8728\n",
            "Epoch 301/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2397 - accuracy: 0.8986 - val_loss: 0.3393 - val_accuracy: 0.8776\n",
            "Epoch 302/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2440 - accuracy: 0.8972 - val_loss: 0.3640 - val_accuracy: 0.8704\n",
            "Epoch 303/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2509 - accuracy: 0.8948 - val_loss: 0.3816 - val_accuracy: 0.8736\n",
            "Epoch 304/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2488 - accuracy: 0.8941 - val_loss: 0.3721 - val_accuracy: 0.8712\n",
            "Epoch 305/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2487 - accuracy: 0.8955 - val_loss: 0.3484 - val_accuracy: 0.8720\n",
            "Epoch 306/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2402 - accuracy: 0.8977 - val_loss: 0.3697 - val_accuracy: 0.8640\n",
            "Epoch 307/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2403 - accuracy: 0.8999 - val_loss: 0.3531 - val_accuracy: 0.8784\n",
            "Epoch 308/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2375 - accuracy: 0.8998 - val_loss: 0.3495 - val_accuracy: 0.8752\n",
            "Epoch 309/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2372 - accuracy: 0.8995 - val_loss: 0.3489 - val_accuracy: 0.8768\n",
            "Epoch 310/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2320 - accuracy: 0.9016 - val_loss: 0.3941 - val_accuracy: 0.8696\n",
            "Epoch 311/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2449 - accuracy: 0.8971 - val_loss: 0.3711 - val_accuracy: 0.8728\n",
            "Epoch 312/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2433 - accuracy: 0.8996 - val_loss: 0.3672 - val_accuracy: 0.8744\n",
            "Epoch 313/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2333 - accuracy: 0.9025 - val_loss: 0.3388 - val_accuracy: 0.8728\n",
            "Epoch 314/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2327 - accuracy: 0.9028 - val_loss: 0.3640 - val_accuracy: 0.8776\n",
            "Epoch 315/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2392 - accuracy: 0.8989 - val_loss: 0.3413 - val_accuracy: 0.8808\n",
            "Epoch 316/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2364 - accuracy: 0.9003 - val_loss: 0.3420 - val_accuracy: 0.8776\n",
            "Epoch 317/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2328 - accuracy: 0.9017 - val_loss: 0.3693 - val_accuracy: 0.8792\n",
            "Epoch 318/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2322 - accuracy: 0.9021 - val_loss: 0.3509 - val_accuracy: 0.8744\n",
            "Epoch 319/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2327 - accuracy: 0.9037 - val_loss: 0.3363 - val_accuracy: 0.8728\n",
            "Epoch 320/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2308 - accuracy: 0.9027 - val_loss: 0.3709 - val_accuracy: 0.8808\n",
            "Epoch 321/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2318 - accuracy: 0.9034 - val_loss: 0.3700 - val_accuracy: 0.8760\n",
            "Epoch 322/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2319 - accuracy: 0.9045 - val_loss: 0.3623 - val_accuracy: 0.8744\n",
            "Epoch 323/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2309 - accuracy: 0.9024 - val_loss: 0.3496 - val_accuracy: 0.8792\n",
            "Epoch 324/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2321 - accuracy: 0.9026 - val_loss: 0.3658 - val_accuracy: 0.8736\n",
            "Epoch 325/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2328 - accuracy: 0.9023 - val_loss: 0.3740 - val_accuracy: 0.8776\n",
            "Epoch 326/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2376 - accuracy: 0.8995 - val_loss: 0.3793 - val_accuracy: 0.8768\n",
            "Epoch 327/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2326 - accuracy: 0.9016 - val_loss: 0.3717 - val_accuracy: 0.8784\n",
            "Epoch 328/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2294 - accuracy: 0.9032 - val_loss: 0.3601 - val_accuracy: 0.8768\n",
            "Epoch 329/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2271 - accuracy: 0.9029 - val_loss: 0.3602 - val_accuracy: 0.8736\n",
            "Epoch 330/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2337 - accuracy: 0.9017 - val_loss: 0.3447 - val_accuracy: 0.8776\n",
            "Epoch 331/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2358 - accuracy: 0.9006 - val_loss: 0.3648 - val_accuracy: 0.8760\n",
            "Epoch 332/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2294 - accuracy: 0.9032 - val_loss: 0.3850 - val_accuracy: 0.8736\n",
            "Epoch 333/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2301 - accuracy: 0.9031 - val_loss: 0.3405 - val_accuracy: 0.8784\n",
            "Epoch 334/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2260 - accuracy: 0.9059 - val_loss: 0.3431 - val_accuracy: 0.8752\n",
            "Epoch 335/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2283 - accuracy: 0.9066 - val_loss: 0.3637 - val_accuracy: 0.8768\n",
            "Epoch 336/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2268 - accuracy: 0.9053 - val_loss: 0.3797 - val_accuracy: 0.8712\n",
            "Epoch 337/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2332 - accuracy: 0.9021 - val_loss: 0.3912 - val_accuracy: 0.8624\n",
            "Epoch 338/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2348 - accuracy: 0.8993 - val_loss: 0.3802 - val_accuracy: 0.8744\n",
            "Epoch 339/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2221 - accuracy: 0.9068 - val_loss: 0.3629 - val_accuracy: 0.8784\n",
            "Epoch 340/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2235 - accuracy: 0.9063 - val_loss: 0.3645 - val_accuracy: 0.8752\n",
            "Epoch 341/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2249 - accuracy: 0.9053 - val_loss: 0.3837 - val_accuracy: 0.8776\n",
            "Epoch 342/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2280 - accuracy: 0.9039 - val_loss: 0.3355 - val_accuracy: 0.8752\n",
            "Epoch 343/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2266 - accuracy: 0.9039 - val_loss: 0.3767 - val_accuracy: 0.8816\n",
            "Epoch 344/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2260 - accuracy: 0.9051 - val_loss: 0.3565 - val_accuracy: 0.8816\n",
            "Epoch 345/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2254 - accuracy: 0.9031 - val_loss: 0.3675 - val_accuracy: 0.8752\n",
            "Epoch 346/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2228 - accuracy: 0.9072 - val_loss: 0.3735 - val_accuracy: 0.8768\n",
            "Epoch 347/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2234 - accuracy: 0.9064 - val_loss: 0.3653 - val_accuracy: 0.8776\n",
            "Epoch 348/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2234 - accuracy: 0.9064 - val_loss: 0.3793 - val_accuracy: 0.8744\n",
            "Epoch 349/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2247 - accuracy: 0.9055 - val_loss: 0.3392 - val_accuracy: 0.8744\n",
            "Epoch 350/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2275 - accuracy: 0.9047 - val_loss: 0.3385 - val_accuracy: 0.8744\n",
            "Epoch 351/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2247 - accuracy: 0.9049 - val_loss: 0.3680 - val_accuracy: 0.8760\n",
            "Epoch 352/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2226 - accuracy: 0.9061 - val_loss: 0.4112 - val_accuracy: 0.8744\n",
            "Epoch 353/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2278 - accuracy: 0.9047 - val_loss: 0.3915 - val_accuracy: 0.8720\n",
            "Epoch 354/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2186 - accuracy: 0.9098 - val_loss: 0.3976 - val_accuracy: 0.8768\n",
            "Epoch 355/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2192 - accuracy: 0.9079 - val_loss: 0.3718 - val_accuracy: 0.8728\n",
            "Epoch 356/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2196 - accuracy: 0.9093 - val_loss: 0.3834 - val_accuracy: 0.8808\n",
            "Epoch 357/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2191 - accuracy: 0.9085 - val_loss: 0.3702 - val_accuracy: 0.8744\n",
            "Epoch 358/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2188 - accuracy: 0.9072 - val_loss: 0.3765 - val_accuracy: 0.8736\n",
            "Epoch 359/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2176 - accuracy: 0.9087 - val_loss: 0.3912 - val_accuracy: 0.8688\n",
            "Epoch 360/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2179 - accuracy: 0.9086 - val_loss: 0.3683 - val_accuracy: 0.8720\n",
            "Epoch 361/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2122 - accuracy: 0.9123 - val_loss: 0.3613 - val_accuracy: 0.8744\n",
            "Epoch 362/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2195 - accuracy: 0.9077 - val_loss: 0.3816 - val_accuracy: 0.8752\n",
            "Epoch 363/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2190 - accuracy: 0.9077 - val_loss: 0.3716 - val_accuracy: 0.8696\n",
            "Epoch 364/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2196 - accuracy: 0.9084 - val_loss: 0.3912 - val_accuracy: 0.8728\n",
            "Epoch 365/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2220 - accuracy: 0.9072 - val_loss: 0.3750 - val_accuracy: 0.8816\n",
            "Epoch 366/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2224 - accuracy: 0.9073 - val_loss: 0.3794 - val_accuracy: 0.8744\n",
            "Epoch 367/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2224 - accuracy: 0.9074 - val_loss: 0.3732 - val_accuracy: 0.8752\n",
            "Epoch 368/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2205 - accuracy: 0.9088 - val_loss: 0.3796 - val_accuracy: 0.8752\n",
            "Epoch 369/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2200 - accuracy: 0.9084 - val_loss: 0.3441 - val_accuracy: 0.8752\n",
            "Epoch 370/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2206 - accuracy: 0.9083 - val_loss: 0.3720 - val_accuracy: 0.8640\n",
            "Epoch 371/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2157 - accuracy: 0.9109 - val_loss: 0.3726 - val_accuracy: 0.8800\n",
            "Epoch 372/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2162 - accuracy: 0.9097 - val_loss: 0.3587 - val_accuracy: 0.8720\n",
            "Epoch 373/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2149 - accuracy: 0.9117 - val_loss: 0.3734 - val_accuracy: 0.8728\n",
            "Epoch 374/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2175 - accuracy: 0.9077 - val_loss: 0.3664 - val_accuracy: 0.8696\n",
            "Epoch 375/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2119 - accuracy: 0.9106 - val_loss: 0.3671 - val_accuracy: 0.8760\n",
            "Epoch 376/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2177 - accuracy: 0.9105 - val_loss: 0.3612 - val_accuracy: 0.8736\n",
            "Epoch 377/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2129 - accuracy: 0.9084 - val_loss: 0.3736 - val_accuracy: 0.8752\n",
            "Epoch 378/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2090 - accuracy: 0.9126 - val_loss: 0.3788 - val_accuracy: 0.8680\n",
            "Epoch 379/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2091 - accuracy: 0.9136 - val_loss: 0.3853 - val_accuracy: 0.8752\n",
            "Epoch 380/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2133 - accuracy: 0.9096 - val_loss: 0.3667 - val_accuracy: 0.8672\n",
            "Epoch 381/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2122 - accuracy: 0.9109 - val_loss: 0.3501 - val_accuracy: 0.8784\n",
            "Epoch 382/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2080 - accuracy: 0.9145 - val_loss: 0.3644 - val_accuracy: 0.8752\n",
            "Epoch 383/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2112 - accuracy: 0.9121 - val_loss: 0.3934 - val_accuracy: 0.8800\n",
            "Epoch 384/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2136 - accuracy: 0.9106 - val_loss: 0.3735 - val_accuracy: 0.8728\n",
            "Epoch 385/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2090 - accuracy: 0.9119 - val_loss: 0.3732 - val_accuracy: 0.8728\n",
            "Epoch 386/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2083 - accuracy: 0.9129 - val_loss: 0.3659 - val_accuracy: 0.8704\n",
            "Epoch 387/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2094 - accuracy: 0.9117 - val_loss: 0.3657 - val_accuracy: 0.8784\n",
            "Epoch 388/400\n",
            "12/12 [==============================] - 30s 3s/step - loss: 0.2067 - accuracy: 0.9136 - val_loss: 0.3623 - val_accuracy: 0.8680\n",
            "Epoch 389/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2164 - accuracy: 0.9087 - val_loss: 0.3925 - val_accuracy: 0.8712\n",
            "Epoch 390/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2128 - accuracy: 0.9114 - val_loss: 0.3845 - val_accuracy: 0.8728\n",
            "Epoch 391/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2058 - accuracy: 0.9144 - val_loss: 0.3839 - val_accuracy: 0.8696\n",
            "Epoch 392/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2038 - accuracy: 0.9152 - val_loss: 0.3632 - val_accuracy: 0.8792\n",
            "Epoch 393/400\n",
            "12/12 [==============================] - 30s 2s/step - loss: 0.2099 - accuracy: 0.9122 - val_loss: 0.3819 - val_accuracy: 0.8744\n",
            "Epoch 394/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2096 - accuracy: 0.9109 - val_loss: 0.3895 - val_accuracy: 0.8768\n",
            "Epoch 395/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2029 - accuracy: 0.9152 - val_loss: 0.3690 - val_accuracy: 0.8808\n",
            "Epoch 396/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2148 - accuracy: 0.9092 - val_loss: 0.3777 - val_accuracy: 0.8704\n",
            "Epoch 397/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2147 - accuracy: 0.9083 - val_loss: 0.3839 - val_accuracy: 0.8728\n",
            "Epoch 398/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2075 - accuracy: 0.9145 - val_loss: 0.4277 - val_accuracy: 0.8528\n",
            "Epoch 399/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2264 - accuracy: 0.9047 - val_loss: 0.3701 - val_accuracy: 0.8728\n",
            "Epoch 400/400\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2134 - accuracy: 0.9109 - val_loss: 0.3676 - val_accuracy: 0.8808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2713f87990>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# fix random seed for reproducibility\n",
        "np.random.seed(9)\n",
        "\n",
        "units = 100\n",
        "drop_out = 0.5\n",
        "model = create_rnn(units, drop_out)\n",
        "#model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(main_path + \"model_checkpoints/model_8.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=2000, epochs=400, validation_data=(x_val, y_val), use_multiprocessing=True, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hRau_lIkrE8"
      },
      "source": [
        "## Part 3 - Making the predictions and visualising the results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = keras.models.load_model(main_path + \"model_checkpoints/model_8.h5\") "
      ],
      "metadata": {
        "id": "a6YVF_Xa4fv3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgJO6qEDksxD"
      },
      "source": [
        "### Evaluating model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "WJsjXZUHcatC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c6f0ab-ed48-4a12-9f53-99fa80f3f42b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5LMNpsNAdin"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "1mFmpe_NAdLW"
      },
      "outputs": [],
      "source": [
        "model.save(main_path + 'LSTM_h5_model_8.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Text_classification_using_pretrained_word_embeddings_by_Waqar_Dongre.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit (conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}